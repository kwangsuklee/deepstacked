{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dataset.shape ==  (245760, 1)\n",
      " dataset2.shape ==  (245760, 1)\n",
      "length of train ==  245760\n",
      "length of test ==  245760\n",
      "length of Total ==  491520\n",
      " Lets start ~!!! go, go! \n",
      "Train on 245728 samples, validate on 245728 samples\n",
      "Epoch 1/1\n",
      "245728/245728 [==============================] - 505s 2ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - mean_absolute_error: 0.0269 - mean_absolute_percentage_error: 1837.5933 - val_loss: 0.0085 - val_mean_squared_error: 0.0085 - val_mean_absolute_error: 0.0863 - val_mean_absolute_percentage_error: 1979.9374\n",
      "Train on 245728 samples, validate on 245728 samples\n",
      "Epoch 1/1\n",
      "245728/245728 [==============================] - 500s 2ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - mean_absolute_error: 0.0247 - mean_absolute_percentage_error: 1857.9488 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_mean_absolute_error: 0.1147 - val_mean_absolute_percentage_error: 1867.8536\n",
      "Train on 245728 samples, validate on 245728 samples\n",
      "Epoch 1/1\n",
      "245728/245728 [==============================] - 506s 2ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - mean_absolute_error: 0.0247 - mean_absolute_percentage_error: 1873.9884 - val_loss: 0.0161 - val_mean_squared_error: 0.0161 - val_mean_absolute_error: 0.1227 - val_mean_absolute_percentage_error: 1834.6446\n",
      "Train on 245728 samples, validate on 245728 samples\n",
      "Epoch 1/1\n",
      "245728/245728 [==============================] - 505s 2ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - mean_absolute_error: 0.0246 - mean_absolute_percentage_error: 1879.4559 - val_loss: 0.0169 - val_mean_squared_error: 0.0169 - val_mean_absolute_error: 0.1259 - val_mean_absolute_percentage_error: 1824.7145\n",
      "Train on 245728 samples, validate on 245728 samples\n",
      "Epoch 1/1\n",
      "245728/245728 [==============================] - 503s 2ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - mean_absolute_error: 0.0244 - mean_absolute_percentage_error: 1876.1891 - val_loss: 0.0175 - val_mean_squared_error: 0.0175 - val_mean_absolute_error: 0.1283 - val_mean_absolute_percentage_error: 1827.1170\n",
      "Train on 245728 samples, validate on 245728 samples\n",
      "Epoch 1/1\n",
      "245728/245728 [==============================] - 508s 2ms/step - loss: 0.0010 - mean_squared_error: 0.0010 - mean_absolute_error: 0.0242 - mean_absolute_percentage_error: 1872.3955 - val_loss: 0.0179 - val_mean_squared_error: 0.0179 - val_mean_absolute_error: 0.1298 - val_mean_absolute_percentage_error: 1820.0278\n",
      "Train on 245728 samples, validate on 245728 samples\n",
      "Epoch 1/1\n",
      "245728/245728 [==============================] - 507s 2ms/step - loss: 8.7919e-04 - mean_squared_error: 8.7919e-04 - mean_absolute_error: 0.0220 - mean_absolute_percentage_error: 1758.8273 - val_loss: 0.0203 - val_mean_squared_error: 0.0203 - val_mean_absolute_error: 0.1392 - val_mean_absolute_percentage_error: 1687.6603\n",
      "Train on 245728 samples, validate on 245728 samples\n",
      "Epoch 1/1\n",
      "245728/245728 [==============================] - 507s 2ms/step - loss: 8.3874e-04 - mean_squared_error: 8.3874e-04 - mean_absolute_error: 0.0214 - mean_absolute_percentage_error: 1761.0709 - val_loss: 0.0210 - val_mean_squared_error: 0.0210 - val_mean_absolute_error: 0.1421 - val_mean_absolute_percentage_error: 1650.6907\n",
      "Train on 245728 samples, validate on 245728 samples\n",
      "Epoch 1/1\n",
      "245728/245728 [==============================] - 503s 2ms/step - loss: 8.2285e-04 - mean_squared_error: 8.2285e-04 - mean_absolute_error: 0.0212 - mean_absolute_percentage_error: 1754.7199 - val_loss: 0.0210 - val_mean_squared_error: 0.0210 - val_mean_absolute_error: 0.1420 - val_mean_absolute_percentage_error: 1645.6691\n",
      "Train on 245728 samples, validate on 245728 samples\n",
      "Epoch 1/1\n",
      "245728/245728 [==============================] - 503s 2ms/step - loss: 8.1584e-04 - mean_squared_error: 8.1584e-04 - mean_absolute_error: 0.0211 - mean_absolute_percentage_error: 1748.8034 - val_loss: 0.0210 - val_mean_squared_error: 0.0210 - val_mean_absolute_error: 0.1420 - val_mean_absolute_percentage_error: 1650.6445\n",
      " Start Prediction ... \n",
      " Train X_1 (bearing 3 x)  Predicting...\n",
      "245728/245728 [==============================] - 149s 607us/step\n",
      " Test X_1 (bearing 3 x) Predicting...\n",
      "245728/245728 [==============================] - 148s 603us/step\n",
      "Train Score: 0.19877 RMSE\n",
      "Test Score: 0.99914 RMSE\n",
      "--------------------------------------------------------\n",
      " history.losses      =  [0.0017555515920525766, 0.001087424610572855, 0.001083074020046456, 0.0010730215327503497, 0.0010619776059558918, 0.0010429126042717427, 0.0008791927753150612, 0.0008387426814241576, 0.0008228508189057625, 0.0008158372881468631]\n",
      " history.mses(=loss) =  [0.0017555515920525766, 0.001087424610572855, 0.001083074020046456, 0.0010730215327503497, 0.0010619776059558918, 0.0010429126042717427, 0.0008791927753150612, 0.0008387426814241576, 0.0008228508189057625, 0.0008158372881468631]\n",
      " history.maes        =  [0.02692932134361018, 0.024743120245580206, 0.024701816280293488, 0.024577117656874366, 0.024447235340760202, 0.024224212259512143, 0.022042142367736328, 0.021439600272606493, 0.02119595546923992, 0.021108340171446773]\n",
      " history.mapes       =  [1837.593250553781, 1857.9487753653375, 1873.9883925839938, 1879.4559427790537, 1876.1890688962126, 1872.3954568736983, 1758.8273428779573, 1761.0708839941465, 1754.7198763681058, 1748.803386400913]\n",
      " history.val_losses     =  [0.008472398413205259, 0.01423348681383909, 0.016146605739522563, 0.0169406028769824, 0.017524234054997992, 0.01788246494113064, 0.020251131823560753, 0.021045733916825855, 0.02101738350583537, 0.02101639373540133]\n",
      " history.val_mses(=loss)=  [0.008472398413205259, 0.01423348681383909, 0.016146605739522563, 0.0169406028769824, 0.017524234054997992, 0.01788246494113064, 0.020251131823560753, 0.021045733916825855, 0.02101738350583537, 0.02101639373540133]\n",
      " history.val_maes       =  [0.0862670544952616, 0.11467085567877028, 0.12273058797550443, 0.12593871035746165, 0.1282715343966399, 0.12980177877455085, 0.13924803126174998, 0.1421095231366757, 0.14199163780724386, 0.1419869926889701]\n",
      " history.val_mapes      =  [1979.9373824661916, 1867.8535769805728, 1834.644601915789, 1824.7144743647018, 1827.1169821365004, 1820.027777625987, 1687.6603312700393, 1650.6907457114974, 1645.6691470696974, 1650.6445489670557]\n",
      "--------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 31, 1)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 31, 16)            640       \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 31, 32)            4224      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 31, 32)            8320      \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 21,777\n",
      "Trainable params: 21,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "model summary ...  None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      " history.losses(mse)     ==  [0.0017555515920525766, 0.001087424610572855, 0.001083074020046456, 0.0010730215327503497, 0.0010619776059558918, 0.0010429126042717427, 0.0008791927753150612, 0.0008387426814241576, 0.0008228508189057625, 0.0008158372881468631]\n",
      " history.val_losses(mse) ==  [0.008472398413205259, 0.01423348681383909, 0.016146605739522563, 0.0169406028769824, 0.017524234054997992, 0.01788246494113064, 0.020251131823560753, 0.021045733916825855, 0.02101738350583537, 0.02101639373540133]\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- The end of code ----------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nplt.plot(history.losses, 'bo')  # Train losses = MSE \\nplt.plot(history.val_losses, 'b') # Test losses = MSE \\n##### 아래 주의, x축은 epochs ### \\nplt.axis([0, epochs, 0.00, 0.04]) ### y-end의 val_loss가 0.22를 넘지 않음.\\n##### x-start(0), x-end(에폭 수), y-start(0), y-and #####\\nplt.title('Model Loss, MAE of Bearing3 X-axis from 14:17 to 16:07')\\nplt.ylabel('Loss(Mean Squared Error)')\\nplt.xlabel('Epoch')\\n#plt.legend(['Train', 'Test'], loc=0)  #plt.plot(,,,label=)\\nplt.legend(['Train', 'Test'])\\nplt.savefig(title+'_MAE_Model_Loss.png')\\n#plt.figure() ## \\nplt.show() \\nprint('--------------------------------------------------------')  \\nplt.plot(history.mapes, 'bo') # Train MAPE\\nplt.plot(history.val_mapes, 'b') # Test MAPE\\n##### 아래 주의, x축은 epochs ### \\nplt.axis([0, epochs, 0.00, 60000]) ### y-end의 val_loss가 30000를 넘지 않음.\\n##### x-start(0), x-end(에폭 수), y-start(0), y-and #####\\nplt.title('Prediction Loss(MAPE) of Bearing3 X-axis from 14:17 to 16:07')\\nplt.ylabel('Loss(Mean Absolute Percentage Error)')\\nplt.xlabel('Epoch')\\n#plt.legend(['Train', 'Test'], loc=0)  #plt.plot(,,,label=)\\nplt.legend(['Train', 'Test'])\\nplt.savefig(title+'_MAPE_Predict_Loss.png')\\n#plt.figure() ## \\nplt.show() \\nprint('--------------------------------------------------------')  \\nplt.plot(history.mses, label='MSE of Train') # Train 0.000x소수점단위\\nplt.plot(history.maes, label='MAE of Train') # Train 0.000x소수점단위\\n#plt.plot(history.mapes, label='mean_absolute_percentage_erro') # 1000~2000단위, 출력만 제외 \\n##### 아래 주의, x축은 epochs ### \\nplt.axis([0, epochs, 0.000, 0.040]) ### y-end의 val_loss가 0.025를 넘지 않음.\\n##### x-start(0), x-end(에폭 수), y-start(0), y-and #####\\nplt.title('Train Loss of Bearing3 X-axis from 12:17 to 14:07') \\nplt.ylabel('Train Loss')\\nplt.xlabel('Train Epoch')\\nplt.legend() ## plt.plot(,label='')\\nplt.savefig(title+'_Train_Loss.png') ###### 수정 \\nplt.show()\\nprint('--------------------------------------------------------') \\nplt.plot(history.val_mses, label='Test_MSE') # Test 0.000x 소수점단위\\nplt.plot(history.val_maes, label='Test_MAE') # Test 0.000x 소수점단위 \\n#plt.plot(history.val_mapes, label='validation_MAPE') # 1000~2000단위, 출력만 제외 \\n##### 아래 주의, x축은 epochs ### \\nplt.axis([0, epochs, 0.00, 0.28]) ### y-end의 val_loss가 0.14를 넘지 않음.\\n##### x-start(0), x-end(에폭 수), y-start(0), y-and #####\\nplt.title('Prediction Test Loss of Bearing3 X-axis from 14:17 to 16:07') \\nplt.ylabel('Test Loss')\\nplt.xlabel('Test Epoch')\\nplt.legend() ## plt.plot(,label='')\\nplt.savefig(title+'_Test_Loss.png') ###### 수정 \\nplt.show()\\nprint('--------------------------------------------------------') \\n# ---------------------------------\\nseries1 = dataframe #dataframe = pandas.read_csv(t, header=None, sep='\\t', usecols=[4], engine='python')\\nseries1.plot(kind='kde') # ‘kde’ : Kernel Density Estimation plot, ‘line’ : line plot (default) \\nplt.title('Density Plots of Train Dataset(Bearing3 X-axis from 12:17 to 14:07)') \\nplt.savefig(title+'_dataset_DensityPlots.png') \\nplt.show()\\n# ---------------------------------\\nseries2 = dataframe2 #dataframe2 = pandas.read_csv(t1, header=None, sep='\\t', usecols=[4], engine='python')\\nseries2.plot(kind='kde') # ‘kde’ : Kernel Density Estimation plot, ‘line’ : line plot (default) \\nplt.title('Density Plots of Test Dataset(Bearing3 X-axis from 14:17 to 16:07)') \\nplt.savefig(title+'_dataset2_DensityPlots.png') \\nplt.show()\\n# ---------------------------------\\n# box and whisker plot\\n# from pandas import DataFrame\\ndf_dataset = pandas.DataFrame(dataset) #Train dataset\\ndf_dataset.boxplot() \\nplt.savefig(title+'_boxplot_dataset.png') \\nplt.show() \\nprint('------- df_dataset.describe() -------')\\nprint(df_dataset.describe())\\n# -------------------------------------\\ndf_trainPredictPlot = pandas.DataFrame(trainPredictPlot)\\ndf_trainPredictPlot.boxplot()  \\nplt.savefig(title+'_boxplot_trainpredict.png') \\nplt.show() \\nprint('------- df_trainPredictPlot.describe() -------')\\nprint(df_trainPredictPlot.describe())\\n# -------------------------------------\\n# box and whisker plot\\n# from pandas import DataFrame\\ndf_dataset2 = pandas.DataFrame(dataset2) #Test dataset\\ndf_dataset2.boxplot() \\nplt.savefig(title+'_boxplot_dataset2.png') \\nplt.show() \\nprint('------- df_dataset2.describe() -------')\\nprint(df_dataset2.describe())\\n# -------------------------------------\\ndf_testPredictPlot = pandas.DataFrame(testPredictPlot)\\ndf_testPredictPlot.boxplot()  # aa.boxplot()에서 aa는 dataframe 타입 \\nplt.savefig(title+'_boxplot_test_predict.png') \\nplt.show() \\nprint('------- df_testPredictPlot.describe() -------')\\nprint(df_testPredictPlot.describe())\\n# -----------------------------------------------------\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Results of this code. \n",
    "\n",
    "Train Score: 0.19877 RMSE\n",
    "Test Score: 0.99914 RMSE\n",
    "--------------------------------------------------------\n",
    " history.losses      =  0.0008158372881468631\n",
    " history.mses(=loss) =  0.0008158372881468631\n",
    " history.maes        =  0.021108340171446773\n",
    " history.mapes       =  1748.803386400913\n",
    " \n",
    " history.val_losses     =  0.02101639373540133\n",
    " history.val_mses(=loss)=  0.02101639373540133\n",
    " history.val_maes       =  0.1419869926889701\n",
    " history.val_mapes      =  1650.6445489670557\n",
    "\n",
    "\"\"\"                        \n",
    "## 18년2월25일.일요일.오후5시20분. 1차 성공. 흑흑흑...\n",
    "# 18년5월1일~6일. Conv 1D - bi-LSTM - LSTM 성공, 이후 최적화 \n",
    "# 18년6월1일.금.오후9시.성공. validation \n",
    "# 18년6월2일.토.오후. 10sets/8column 중에 1column 추출 성공.  pandas.read_csv ( , ,usecols=[4] )\n",
    "# 18년6월3일.일.오후7시.성공. loss/epoch graph, model.fit(, , , .. callbacks=[history])\n",
    "# 18년6월6일.수. loss/epoch graph 일부 상세 수정\n",
    "#  Timestep = 29,  (19는 Loss크다)\n",
    "#  A Type code : User defined History Class \n",
    "#       class LossHistory(keras.callbacks.Callback):  #history = LossHistory()\n",
    "#             def ... def ... \n",
    "#        model.fit( )  # # because of if loop for fit() \n",
    "#  B Type code : Default typed History Class \n",
    "#       compile \n",
    "#       history = model.fit( )\n",
    "#       score = model.evaluate \n",
    "# Kwangsuk.Lee \n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas     \n",
    "from pandas import read_csv\n",
    "import math\n",
    "import keras      \n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dense, Input, Flatten, Add, concatenate \n",
    "from keras.layers import Activation, BatchNormalization, regularizers, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D  # Addition \n",
    "from keras.layers import LSTM, Bidirectional # 추가 3. \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error #Mean squared error regression loss\n",
    "from sklearn.metrics import mean_absolute_error # Mean absolute error regression loss\n",
    "# http://scikit-learn.org/stable/modules/classes.html \n",
    "#http://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\n",
    "# http://scikit-learn.org/stable/modules/classes.html\n",
    "from sklearn.metrics import recall_score, precision_score # New \n",
    "from sklearn.metrics import f1_score #f1_score(y_true, y_pred[, labels, …])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing  # New \n",
    "#from keras.layers import normalization ### 추가 keras.layers.normalization.BatchNormalization() \n",
    "#from keras.layers import Dropout  ### 추가 keras.layers.Dropout()\n",
    "\n",
    "\n",
    "title = '180602_05_lstm_bilstm_' \n",
    "epochs = 10 \n",
    "batch_size = 128  # 128  # 64, 128, do not 256, i.e. in case of 128, 1 epoch = 9minutes    \n",
    "                   # 245759 - timestep 31 = 245728 / 112 = 0 \n",
    "                   # In a stateful network, you should only pass inputs with a number of samples that can be divided by the batch size. Found: 245728 samples \n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):   #history = LossHistory()\n",
    "    def init(self):         # history.init() \n",
    "        self.losses = []\n",
    "        #self.accs = []\n",
    "        self.val_losses = []\n",
    "        #self.val_accs = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.mapes = [] \n",
    "        self.val_mses = []\n",
    "        self.val_maes = []\n",
    "        self.val_mapes = []   \n",
    "    \n",
    "    def on_epoch_end(self, batch, logs={}): \n",
    "        self.losses.append(logs.get('loss'))\n",
    "        #self.accs.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        #self.val_accs.append(logs.get('val_accuracy')) \n",
    "        self.mses.append(logs.get('mean_squared_error')) \n",
    "        self.maes.append(logs.get('mean_absolute_error')) \n",
    "        self.mapes.append(logs.get('mean_absolute_percentage_error')) \n",
    "        self.val_mses.append(logs.get('val_mean_squared_error')) \n",
    "        self.val_maes.append(logs.get('val_mean_absolute_error')) \n",
    "        self.val_mapes.append(logs.get('val_mean_absolute_percentage_error'))       \n",
    "# end of the class \n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, timesteps): #기존def create_dataset(dataset, timesteps=1): 여기서 -1삭제\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-timesteps-1):\n",
    "        a = dataset[i:(i+timesteps), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + timesteps, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "# fix random seed for reproducibility \n",
    "numpy.random.seed() \n",
    "\n",
    "# load the dataset\n",
    "t = '00_Train_2003.11.25.12.17_14.07_12sets.csv' # 12sets \n",
    "dataframe = pandas.read_csv(t, header=None, sep='\t', usecols=[4], engine='python')  \n",
    "dataset = dataframe.values  # 여기는 항상 t 시점\n",
    "dataset = dataset.astype('float32')\n",
    "print(' dataset.shape == ', dataset.shape)\n",
    "\n",
    "t1 = '00_Test_2003.11.25.14.17_16.07_12sets.csv' # 12sets \n",
    "dataframe2 = pandas.read_csv(t1, header=None, sep='\t', usecols=[4], engine='python')\n",
    "dataset2 = dataframe2.values  # Prediction Target(label) Data\n",
    "dataset2 = dataset2.astype('float32')\n",
    "print(' dataset2.shape == ', dataset2.shape)\n",
    "\n",
    "# normalize the dataset ---------------- # 18.2.25. \n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1)) # New 18.3.16.금.14시34분\n",
    "dataset2 = scaler2.fit_transform(dataset2)\n",
    "\n",
    "# split into train and test sets ----------------\n",
    "train_size = int(len(dataset)) # train 102400/5(batch_size)=  ,102396 ->102380   \n",
    "test_size = int(len(dataset2)) # test 20480/5(batch_size)=   ,20478\n",
    "train = dataset[0:train_size,:] \n",
    "test = dataset2[0:test_size,:]\n",
    "print('length of train == ', int(len(dataset)))\n",
    "print('length of test == ', int(len(dataset2))) \n",
    "print('length of Total == ', int(len(dataset))+int(len(dataset2))) \n",
    "print(' Lets start ~!!! go, go! ') \n",
    "\n",
    "# reshape into X=t and Y=t+1\n",
    "features = 1 \n",
    "timesteps = 31 # 31(32), timesteps=lookback은 한 스텝을 예측 \n",
    "\n",
    "trainX, trainY = create_dataset(train, timesteps)\n",
    "testX, testY = create_dataset(test, timesteps)\n",
    "# reshape input to be [samples, time steps, features] 타임스텝이란 하나의 샘플에 포함된 시퀀스 갯수\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "######################################### with K.tf.device('/gpu:0'):  => GPU usage\n",
    "import keras.backend.tensorflow_backend as K \n",
    "with K.tf.device('/gpu:0'):\n",
    "    \n",
    "    input_1 = Input(shape=(timesteps, features))  # timesteps , 1  (batch = 128)\n",
    "        \n",
    "    ls_11 = (Bidirectional(LSTM(8, return_sequences=True)))(input_1) \n",
    "    ls_12 = (Bidirectional(LSTM(16, return_sequences=True)))(ls_11) \n",
    "    ls_13 = (LSTM(32, return_sequences=True))(ls_12) \n",
    "    ls_14 = (LSTM(32))(ls_13) \n",
    "    \n",
    "    dense_11 = Dense(8, activation='relu')(ls_14)\n",
    "    output_1 = Dense(1, activation='relu')(dense_11)\n",
    "    model = Model(inputs=[input_1], outputs=[output_1]) # multi-input, multi-output \n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',\n",
    "                  metrics=['mse', 'mae', 'mape'])  \n",
    "    \n",
    "    epochs=epochs    # Above grobal variable  \n",
    "    \n",
    "    history = LossHistory() # because of if loop for fit() \n",
    "    history.init()          # because of if loop for fit()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        model.fit(trainX, trainY, epochs=1, batch_size=batch_size,\n",
    "                  shuffle=False, validation_data=(testX, testY), \n",
    "                  callbacks=[history])\n",
    "        model.reset_states() # shuffle=False 순서대로 출력의미, LSTM레이어가 여럿일때는 fit(return_sequence=True) \n",
    "\n",
    "# make predictions\n",
    "print(' Start Prediction ... ')   \n",
    "print(' Train X_1 (bearing 3 x)  Predicting...') \n",
    "trainPredict = model.predict(trainX, batch_size=batch_size, verbose = 1)\n",
    "model.reset_states()\n",
    "print(' Test X_1 (bearing 3 x) Predicting...') \n",
    "testPredict = model.predict(testX, batch_size=batch_size, verbose = 1)\n",
    "\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "\n",
    "testPredict = scaler.inverse_transform(testPredict) #scaler2 \n",
    "testY = scaler.inverse_transform([testY]) #scaler2 \n",
    "\n",
    "# calculate root mean squared error \n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.5f RMSE' % (trainScore))  ## 1-RMSE = Accuracy %  \n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.5f RMSE' % (testScore))  ## 1-RMSE = Accuracy %  \n",
    "print('--------------------------------------------------------') \n",
    "print(' history.losses      = ', history.losses) # loss == mse \n",
    "print(' history.mses(=loss) = ', history.mses)  # loss == mse \n",
    "print(' history.maes        = ', history.maes)\n",
    "print(' history.mapes       = ', history.mapes)\n",
    "print(' history.val_losses     = ', history.val_losses)  # loss == mse \n",
    "print(' history.val_mses(=loss)= ', history.val_mses) # loss == mse \n",
    "print(' history.val_maes       = ', history.val_maes)\n",
    "print(' history.val_mapes      = ', history.val_mapes)\n",
    "print('--------------------------------------------------------')      \n",
    "# ---------------------------------\n",
    "# print to # Layer, Shape, Parameter \n",
    "print('model summary ... ', model.summary())  # keras.models.model()\n",
    "# ---------------------------------\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[timesteps:len(trainPredict)+timesteps, :] = trainPredict\n",
    "# shift test predictions for plotting ... NEW\n",
    "testPredictPlot = numpy.empty_like(dataset2)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "#testPredictPlot[len(trainPredict)+(timesteps*2)+1:len(dataset2)-1, :] = testPredict\n",
    "testPredictPlot[timesteps:len(testPredict)+timesteps, :] = testPredict\n",
    "# ---------------------------------\n",
    "plt.plot(scaler.inverse_transform(dataset), label='Groundtruth')\n",
    "plt.plot(trainPredictPlot, label='Training')\n",
    "plt.title('Train of Bearing3 X-axis from 12:17 to 14:07') \n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Samples')\n",
    "plt.legend() ## plt.plot(,label='')\n",
    "plt.savefig(title+'_Train_groundtruth.png') ###### 수정 \n",
    "plt.show()\n",
    "# ---------------------------------\n",
    "plt.plot(scaler2.inverse_transform(dataset2), label='Groundtruth')\n",
    "#plt.plot(trainPredictPlot) 불필요, 아래 test display\n",
    "plt.plot(testPredictPlot, label='Test')\n",
    "plt.title('Prediction Test of Bearing3 X-axis from 14:17 to 16:07') \n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Samples')\n",
    "plt.legend() ## plt.plot(,label='')\n",
    "plt.savefig(title+'_Test_groundtruth.png')  ###### 수정 \n",
    "plt.show()\n",
    "print('--------------------------------------------------------')  \n",
    "print(' history.losses(mse)     == ', history.losses) \n",
    "print(' history.val_losses(mse) == ', history.val_losses)\n",
    "print('--------------------------------------------------------') \n",
    "plt.plot(history.mses, 'b--', label='MSE of Train') # Train 0.000x소수점단위\n",
    "plt.plot(history.maes, 'b:', label='MAE of Train') # Train 0.000x소수점단위\n",
    "plt.plot(history.val_mses, 'r+', label='MSE of Test') # Test 0.000x 소수점단위\n",
    "plt.plot(history.val_maes, 'ro', label='MAE of Test') # Test 0.000x 소수점단위 \n",
    "plt.title('Train loss and Test loss of Bearing3 X-axis') \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend() ## plt.plot(,label='')\n",
    "plt.savefig(title+'_mse_mae.png') ###### 수정 \n",
    "plt.show()\n",
    "print('----------------------- The end of code ----------------') \n",
    "\"\"\"\n",
    "plt.plot(history.losses, 'bo')  # Train losses = MSE \n",
    "plt.plot(history.val_losses, 'b') # Test losses = MSE \n",
    "##### 아래 주의, x축은 epochs ### \n",
    "plt.axis([0, epochs, 0.00, 0.04]) ### y-end의 val_loss가 0.22를 넘지 않음.\n",
    "##### x-start(0), x-end(에폭 수), y-start(0), y-and #####\n",
    "plt.title('Model Loss, MAE of Bearing3 X-axis from 14:17 to 16:07')\n",
    "plt.ylabel('Loss(Mean Squared Error)')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.legend(['Train', 'Test'], loc=0)  #plt.plot(,,,label=)\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.savefig(title+'_MAE_Model_Loss.png')\n",
    "#plt.figure() ## \n",
    "plt.show() \n",
    "print('--------------------------------------------------------')  \n",
    "plt.plot(history.mapes, 'bo') # Train MAPE\n",
    "plt.plot(history.val_mapes, 'b') # Test MAPE\n",
    "##### 아래 주의, x축은 epochs ### \n",
    "plt.axis([0, epochs, 0.00, 60000]) ### y-end의 val_loss가 30000를 넘지 않음.\n",
    "##### x-start(0), x-end(에폭 수), y-start(0), y-and #####\n",
    "plt.title('Prediction Loss(MAPE) of Bearing3 X-axis from 14:17 to 16:07')\n",
    "plt.ylabel('Loss(Mean Absolute Percentage Error)')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.legend(['Train', 'Test'], loc=0)  #plt.plot(,,,label=)\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.savefig(title+'_MAPE_Predict_Loss.png')\n",
    "#plt.figure() ## \n",
    "plt.show() \n",
    "print('--------------------------------------------------------')  \n",
    "plt.plot(history.mses, label='MSE of Train') # Train 0.000x소수점단위\n",
    "plt.plot(history.maes, label='MAE of Train') # Train 0.000x소수점단위\n",
    "#plt.plot(history.mapes, label='mean_absolute_percentage_erro') # 1000~2000단위, 출력만 제외 \n",
    "##### 아래 주의, x축은 epochs ### \n",
    "plt.axis([0, epochs, 0.000, 0.040]) ### y-end의 val_loss가 0.025를 넘지 않음.\n",
    "##### x-start(0), x-end(에폭 수), y-start(0), y-and #####\n",
    "plt.title('Train Loss of Bearing3 X-axis from 12:17 to 14:07') \n",
    "plt.ylabel('Train Loss')\n",
    "plt.xlabel('Train Epoch')\n",
    "plt.legend() ## plt.plot(,label='')\n",
    "plt.savefig(title+'_Train_Loss.png') ###### 수정 \n",
    "plt.show()\n",
    "print('--------------------------------------------------------') \n",
    "plt.plot(history.val_mses, label='Test_MSE') # Test 0.000x 소수점단위\n",
    "plt.plot(history.val_maes, label='Test_MAE') # Test 0.000x 소수점단위 \n",
    "#plt.plot(history.val_mapes, label='validation_MAPE') # 1000~2000단위, 출력만 제외 \n",
    "##### 아래 주의, x축은 epochs ### \n",
    "plt.axis([0, epochs, 0.00, 0.28]) ### y-end의 val_loss가 0.14를 넘지 않음.\n",
    "##### x-start(0), x-end(에폭 수), y-start(0), y-and #####\n",
    "plt.title('Prediction Test Loss of Bearing3 X-axis from 14:17 to 16:07') \n",
    "plt.ylabel('Test Loss')\n",
    "plt.xlabel('Test Epoch')\n",
    "plt.legend() ## plt.plot(,label='')\n",
    "plt.savefig(title+'_Test_Loss.png') ###### 수정 \n",
    "plt.show()\n",
    "print('--------------------------------------------------------') \n",
    "# ---------------------------------\n",
    "series1 = dataframe #dataframe = pandas.read_csv(t, header=None, sep='\t', usecols=[4], engine='python')\n",
    "series1.plot(kind='kde') # ‘kde’ : Kernel Density Estimation plot, ‘line’ : line plot (default) \n",
    "plt.title('Density Plots of Train Dataset(Bearing3 X-axis from 12:17 to 14:07)') \n",
    "plt.savefig(title+'_dataset_DensityPlots.png') \n",
    "plt.show()\n",
    "# ---------------------------------\n",
    "series2 = dataframe2 #dataframe2 = pandas.read_csv(t1, header=None, sep='\t', usecols=[4], engine='python')\n",
    "series2.plot(kind='kde') # ‘kde’ : Kernel Density Estimation plot, ‘line’ : line plot (default) \n",
    "plt.title('Density Plots of Test Dataset(Bearing3 X-axis from 14:17 to 16:07)') \n",
    "plt.savefig(title+'_dataset2_DensityPlots.png') \n",
    "plt.show()\n",
    "# ---------------------------------\n",
    "# box and whisker plot\n",
    "# from pandas import DataFrame\n",
    "df_dataset = pandas.DataFrame(dataset) #Train dataset\n",
    "df_dataset.boxplot() \n",
    "plt.savefig(title+'_boxplot_dataset.png') \n",
    "plt.show() \n",
    "print('------- df_dataset.describe() -------')\n",
    "print(df_dataset.describe())\n",
    "# -------------------------------------\n",
    "df_trainPredictPlot = pandas.DataFrame(trainPredictPlot)\n",
    "df_trainPredictPlot.boxplot()  \n",
    "plt.savefig(title+'_boxplot_trainpredict.png') \n",
    "plt.show() \n",
    "print('------- df_trainPredictPlot.describe() -------')\n",
    "print(df_trainPredictPlot.describe())\n",
    "# -------------------------------------\n",
    "# box and whisker plot\n",
    "# from pandas import DataFrame\n",
    "df_dataset2 = pandas.DataFrame(dataset2) #Test dataset\n",
    "df_dataset2.boxplot() \n",
    "plt.savefig(title+'_boxplot_dataset2.png') \n",
    "plt.show() \n",
    "print('------- df_dataset2.describe() -------')\n",
    "print(df_dataset2.describe())\n",
    "# -------------------------------------\n",
    "df_testPredictPlot = pandas.DataFrame(testPredictPlot)\n",
    "df_testPredictPlot.boxplot()  # aa.boxplot()에서 aa는 dataframe 타입 \n",
    "plt.savefig(title+'_boxplot_test_predict.png') \n",
    "plt.show() \n",
    "print('------- df_testPredictPlot.describe() -------')\n",
    "print(df_testPredictPlot.describe())\n",
    "# -----------------------------------------------------\n",
    "\"\"\"\n",
    "# end of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
